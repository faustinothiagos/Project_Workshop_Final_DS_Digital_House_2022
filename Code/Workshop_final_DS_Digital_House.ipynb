{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bda055ef",
   "metadata": {},
   "source": [
    "<a id=\"section_CART\"></a> \n",
    "## Workshop Final DS Digital House"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fff9f37",
   "metadata": {},
   "source": [
    "<h1 style='background:#3f4788; border:2; font-size:300%; font-weight: bold;\n",
    "color:white; padding:20px'><center>Análise de Conjunto de Dados de Credit Score</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc0069e",
   "metadata": {},
   "source": [
    "<center><img src = \"https://storage.googleapis.com/kaggle-datasets-images/2289007/3846912/ad5e128929f5ac26133b67a6110de7c0/dataset-cover.jpg?t=2022-06-22-14-33-45\" width = 900 height = 400/></center>\n",
    "\n",
    "\n",
    "Você está trabalhando como cientista de dados em uma empresa financeira global. Ao longo dos anos, a empresa coletou dados bancários básicos e reuniu muitas informações relacionadas a crédito de alguns clientes. A gerência quer construir um sistema inteligente para segregar as pessoas em faixas de pontuação de crédito para reduzir os esforços manuais e melhorar a precisão das apurações.\n",
    "\n",
    "Tarefa\n",
    "Dadas as informações relacionadas ao crédito de uma pessoa, construa um modelo de aprendizado de máquina que possa classificar a pontuação de crédito.\n",
    "\n",
    "\n",
    "<a id='top'></a>\n",
    "<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n",
    "\n",
    "<h1 style='background:#3f4788; border:0; border-radius: 10px; color:white;padding:20px'><center> Sumário </center></h1>\n",
    "\n",
    "### [**1. Importando bibliotecas e carregando dados**](#title-one)\n",
    "\n",
    "### [**2. Data Wrangling, EDA e Visualizações**](#title-two)\n",
    "\n",
    "### [**3. Limpeza de dados**](#title-three)\n",
    "\n",
    "### [**4. Pré-processamento de Dados**](#title-four)\n",
    "\n",
    "### [**5. Feature Importance e Feature Selection**](#title-five)\n",
    "\n",
    "### [**6. Modelagem**](#title-six)\n",
    "\n",
    "<a id=\"title-one\"></a>\n",
    "<h1 style='background:#3f4788; border:2; border-radius: 10px; color:white;padding:20px'><center>Importando bibliotecas e carregando dados</center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e20447-fa04-49f7-9c33-d45a0302436d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import seaborn as sns\n",
    "pd.set_option('display.max_columns', None)\n",
    "import missingno as msno\n",
    "#from dataprep.eda import plot, plot_correlation, create_report, plot_missing\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Definindo fontes\n",
    "font = {'family' : 'DejaVu Sans',\n",
    "        'weight' : 'bold',\n",
    "        'size'   : 30}\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be4e30a",
   "metadata": {},
   "source": [
    "## Importando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14215666-b368-48fb-924b-2a312f82d31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importando bases de treino e teste\n",
    "df_test = pd.read_csv(r\"../DataSet/test.csv\", low_memory = False)\n",
    "df_train = pd.read_csv(r\"../DataSet/train.csv\", low_memory = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46feb9d6",
   "metadata": {},
   "source": [
    "## Agrupando os datasets para limpar os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6043a39-23f4-45c9-994b-f60e060dd44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # incluindo colunas para sperar os dados da mesma maneira que estavam originalmente\n",
    "# df_train['test'] = 0\n",
    "# df_test['test'] = 1\n",
    "\n",
    "# # incluindo coluna de score com nan nos dados de teste\n",
    "# df_test['Credit_Score'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b017eb56-cef5-4e7c-a259-db1177e62e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenando os datasets ja que eles tem as mesmas colunas\n",
    "\n",
    "df_total = pd.concat([df_train, df_test], ignore_index = True)\n",
    "df_orig = df_total.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b47c8cf-93dc-43dd-840b-f22b28d11353",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('dados de treino: ', df_train.shape)\n",
    "print('dados de teste: ', df_test.shape)\n",
    "print('todos os dados agrupados: ', df_total.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a64601a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2303b635",
   "metadata": {},
   "source": [
    "## Colunas dataset:\n",
    "\n",
    "* ID - Identificador de entrada\n",
    "* Customer_ID - ID cliente\n",
    "* Month - Mês do ano\n",
    "* Name - nome do cliente\n",
    "* Age - Idade Cliente\n",
    "* SSN - Social Security Number (CPF no Brasil)\n",
    "* Occupation - Ocupação do cliente\n",
    "* Annual_Income - renda anual\n",
    "* Monthly_Inhand_Salary - Salario mensal do cliente\n",
    "* Num_Bank_Accounts - quantidade de contas em bancos\n",
    "* Num_Credit_Card - quantidade de cartões de crédito\n",
    "* Interest_Rate - taxa de juros cartão de crédito\n",
    "* Num_of_Loan - Quantidade de empréstimos feitos no banco\n",
    "* Type_of_Loan - tipo de empréstimo feito pelo cliente\n",
    "* Delay_from_due_date - qtd. de dias de atraso pagamento cartão\n",
    "* Num_of_Delayed_Payment - Média de pagamentos atrasado pelo cliente\n",
    "* Changed_Credit_Limit - Variação percentual de limite do cartão de crédito\n",
    "* Num_Credit_Inquiries - Quantidade de \"cobranças\" no cartão\n",
    "* Credit_Mix - mix de crédito do cliente\n",
    "* Outstanding_Debt - restante à ser pago da dívida\n",
    "* Credit_Utilization_Ratio - Taxa de utlização do cartão de crédito\n",
    "* Credit_History_Age - Tempo de histórico de crédito do cliente\n",
    "* Payment_of_Min_Amount - Pagamento minimo\n",
    "* Total_EMI_per_month - Pagamento fixo em dolares por mes\n",
    "* Amount_invested_monthly - Quantidade de dinheiro investido pelo cliente mensalmente\n",
    "* Payment_Behaviour - Comportamento de pagamento cliente\n",
    "* Monthly_Balance - Saldo Mensal Cliente\n",
    "* Credit_Score - Target, Pontuação de uso de crédito\n",
    "* test - coluna utilizada para separar o dataset nos dados de treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dffc3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93757490",
   "metadata": {},
   "source": [
    "#### Porcentagem de dados faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6fda0a-5e14-4540-a353-70cd2de3e718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta função define a quantidade % de dados faltantes\n",
    "def plot_nas(df: pd.DataFrame):\n",
    "    if df.isnull().sum().sum() != 0:\n",
    "        na_df = (df.isnull().sum() / len(df)) * 100      \n",
    "        na_df = na_df.drop(na_df[na_df == 0].index).sort_values(ascending=False)\n",
    "        missing_data = pd.DataFrame({'Missing Ratio %' :na_df})\n",
    "        missing_data.plot(kind = \"barh\", color='#087E8B')\n",
    "        plt.title(\"% de dados faltantes\")\n",
    "        plt.show()\n",
    "    else:\n",
    "        print('No NAs found')\n",
    "        \n",
    "plot_nas(df_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f24941-fad9-4589-918c-3a04e1d74f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.bar(df_total, color='#087E8B');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca82a35c",
   "metadata": {},
   "source": [
    "## Checando os principais valores de algumas colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3094570b-97f6-4399-8e02-6a30b5d55492",
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas = df_total.columns\n",
    "\n",
    "for coluna in colunas:\n",
    "    print('Variavel: ', coluna)\n",
    "    print(20*'-')\n",
    "    print(df_total[coluna].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f24684",
   "metadata": {},
   "source": [
    "### Observações\n",
    "\n",
    "1. Colunas numéricas com \"_\" ok\n",
    "    * Age,\n",
    "    * Annual_Income,\n",
    "    * Monthly_Inhand_Salary,\n",
    "    * Num_Bank_Accounts,\n",
    "    * Num_Credit_Card,\n",
    "    * Interest_Rate\n",
    "    * Num_of_Loan\n",
    "    * Delay_from_due_date\n",
    "    * Num_of_Delayed_Payment\n",
    "    * Changed_Credit_Limit\n",
    "    * Num_Credit_Inquiries\n",
    "    * Outstanding_Debt\n",
    "    * Credit_Utilization_Ratio\n",
    "    * Total_EMI_per_month\n",
    "    * Amount_invested_monthly\n",
    "    * Monthly_Balance\n",
    "2. SSN #F%$D@*&8 ok\n",
    "3. Occupation _______ ok\n",
    "4. Type_of_Loan - transformar em lista e indexar\n",
    "5. Changed_Credit_Limit \"_\" -> NaN ok\n",
    "6. Credit_Mix \"_\" -> NaN ok\n",
    "7. Credit_History_Age Transformar em qtd. Meses\n",
    "8. Payment_of_Min_Amount \"NM\" -> NaN ok\n",
    "9. Payment_Behaviour \"!@9#%8\" -> NaN e transformar dado ok"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4740c1",
   "metadata": {},
   "source": [
    "<a id=\"title-two\"></a>\n",
    "<h1 style='background:#3f4788; border:2; border-radius: 10px; color:white;padding:20px'><center>Data Wrangling, EDA e Visualizações</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4067fb8",
   "metadata": {},
   "source": [
    "## Ajustando os campos númericos que estão definidos como string por terem underlines em alguns registros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c61aba-01c7-4463-aa45-d8347264b635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Campos númericos que estão como string - retirar underline dos numeros\n",
    "\n",
    "colunas_ul = ['Age', 'Annual_Income', 'Num_of_Loan', 'Num_of_Delayed_Payment',\n",
    "              'Changed_Credit_Limit', 'Outstanding_Debt', 'Amount_invested_monthly', 'Monthly_Balance']\n",
    "for row in colunas_ul:\n",
    "    df_total[row] = df_total[row].str.replace(r'_+', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d28cebe",
   "metadata": {},
   "source": [
    "## Data Wrangling\n",
    "\n",
    "* Limpeza nos campos com dados inconsistentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7e47c7-c875-444a-9e8f-0e9912ba107d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo coluna ID, completamente inútil para a análise\n",
    "df_total.drop(['ID'], axis = 1, inplace = True)\n",
    "\n",
    "# removendo caracter estranho do SSN\n",
    "df_total['SSN'].replace('#F%$D@*&8', np.NaN, inplace=True)\n",
    "\n",
    "# removendo os underlines e colocando NaN na coluna Occupation\n",
    "df_total['Occupation'].replace('_______', np.NaN, inplace=True)\n",
    "\n",
    "df_total['Changed_Credit_Limit'].replace(['_', ''], np.NaN, inplace=True)\n",
    "\n",
    "df_total['Credit_Mix'].replace('_', np.NaN, inplace=True)\n",
    "\n",
    "df_total['Payment_of_Min_Amount'].replace('NM', np.NaN, inplace=True)\n",
    "\n",
    "df_total['Payment_Behaviour'].replace('!@9#%8', np.NaN, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d36260a",
   "metadata": {},
   "source": [
    "### Convertendo campo de credit history para qtd. Meses\n",
    "* 1 year = 12 months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26b9bf0-6f9b-4b54-8aba-044d09065ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convertendo Credit_History_Age em quantidade de meses\n",
    "def converter_mes(x):\n",
    "    if pd.notnull(x):\n",
    "        ano = int(x.split(' ')[0])\n",
    "        mes = int(x.split(' ')[3])\n",
    "        return (ano*12)+mes\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "df_total['Credit_History_age'] = df_total['Credit_History_Age'].apply(lambda x: converter_mes(x)).astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8935c4dc",
   "metadata": {},
   "source": [
    "### Removendo 'and' no preenchimento do campo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f62e9c-08e3-47db-b61f-0d688c631abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total['Type_of_Loan_ajustado'] = df_total['Type_of_Loan'].replace(\"[abc]* and \", \" \", regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5998cde",
   "metadata": {},
   "source": [
    "### Conversão de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b81b1e-8992-4806-9e28-5b45f5251e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#criando dicionario e convertendo os dados\n",
    "\n",
    "dicionario_conversao = {\n",
    "    'Age': int,\n",
    "    'Num_Bank_Accounts': int,\n",
    "    'Num_Credit_Card': int,\n",
    "    'Num_of_Loan': int,\n",
    "    'Num_of_Delayed_Payment': int,\n",
    "    'Annual_Income' : float,\n",
    "    'Monthly_Inhand_Salary' : float,\n",
    "    'Interest_Rate' : float,\n",
    "    'Delay_from_due_date' : float,\n",
    "    'Changed_Credit_Limit' : float,\n",
    "    'Num_Credit_Inquiries' : float,\n",
    "    'Outstanding_Debt' : float,\n",
    "    'Credit_Utilization_Ratio' : float,\n",
    "    'Changed_Credit_Limit' : float,\n",
    "    'Amount_invested_monthly' : float,\n",
    "    'Total_EMI_per_month' : float,\n",
    "    'Num_of_Delayed_Payment' : float,\n",
    "    'Monthly_Balance' : float,\n",
    "    # 'ID' : object,\n",
    "    'Customer_ID' : object,\n",
    "    'Name' : object,\n",
    "    'Month' : object,\n",
    "    'SSN' : object,\n",
    "    'Type_of_Loan' : object,\n",
    "    'Occupation' : object,\n",
    "    'Credit_Mix' : object,\n",
    "    'Payment_of_Min_Amount' : object,\n",
    "    'Payment_Behaviour' : object\n",
    "    # 'test' : object\n",
    "    }\n",
    "# aplicando as type para variaveis\n",
    "\n",
    "df_total = df_total.astype(dicionario_conversao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c231ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convertendo mes para encoding\n",
    "\n",
    "import datetime\n",
    "\n",
    "df_total['Month'] = df_total['Month'].apply(lambda x: datetime.datetime.strptime(x, '%B').month)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da23e315",
   "metadata": {},
   "source": [
    "### Visualização dos dados pré-limpeza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf3f791-5ea5-43ec-90cb-b27c48ae61b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "numCols = ['Monthly_Inhand_Salary', 'Delay_from_due_date', 'Credit_Utilization_Ratio']\n",
    "\n",
    "for col in numCols:\n",
    "    plt.figure(figsize=(180,6))\n",
    "    sns.displot(x=col,data=df_total, hue='Credit_Score', palette=[\"#ff006e\", \"#83c5be\", \"#3a0ca3\"])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a86892",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropando na\n",
    "\n",
    "df_nonull = df_total.dropna()\n",
    "\n",
    "# pegando indices\n",
    "\n",
    "# df2 = df_nonull.groupby([\"Customer_ID\"])[\"Month\"].nlargest(1)\n",
    "\n",
    "# list comprehension para juntar os índices\n",
    "\n",
    "# indice_final = [i[1] for i in df2.index.values]\n",
    "\n",
    "# aplicando máscara, pegando somente linha do último mês de cada usuário\n",
    "\n",
    "# df_nonull_uniqueCID = df_total.loc[indice_final]\n",
    "\n",
    "df_nonull_uniqueCID = df_nonull.copy() #desistimos de usar esse fatiamento e mantivemos para não renomear todas as variáveis depois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084a4b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agegroup = df_nonull_uniqueCID.copy()\n",
    "\n",
    "df_agegroup[\"Age_Group\"] = pd.cut(df_agegroup.Age,\n",
    "                             bins=[14, 25, 30, 45, 60, 100],\n",
    "                             labels=[\"14-25\", \"25-30\", \"30-45\", \"45-60\", \"60-100\"],\n",
    "                            )\n",
    "\n",
    "age_groups = (df_agegroup.groupby([\"Age_Group\", \"Credit_Score\"])[\"Outstanding_Debt\", \"Annual_Income\", \"Num_Bank_Accounts\", \"Num_Credit_Card\"].sum().reset_index())\n",
    "\n",
    "sns.catplot(data=age_groups,\n",
    "                x=\"Age_Group\",\n",
    "                y=\"Outstanding_Debt\",\n",
    "                height=7,\n",
    "                aspect=1,\n",
    "                col=\"Credit_Score\",\n",
    "                kind=\"bar\",\n",
    "                ci=None,\n",
    "                palette='viridis'\n",
    "               ).set_axis_labels(\"Faixa Etária\", \"Soma de Dívida\", size=20, fontweight=\"bold\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7ae769",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agegroup = df_nonull_uniqueCID.copy()\n",
    "\n",
    "df_agegroup[\"Age_Group\"] = pd.cut(df_agegroup.Age,\n",
    "                             bins=[14, 25, 30, 45, 60, 100],\n",
    "                             labels=[\"14-25\", \"25-30\", \"30-45\", \"45-60\", \"60-100\"],\n",
    "                            )\n",
    "\n",
    "age_groups = (df_agegroup.groupby([\"Age_Group\", 'Credit_Score'])['Total_EMI_per_month'].mean().reset_index())\n",
    "\n",
    "sns.catplot(data=age_groups,\n",
    "                x=\"Age_Group\",\n",
    "                y=\"Total_EMI_per_month\",\n",
    "                hue='Credit_Score',\n",
    "                height=7,\n",
    "                aspect=1,\n",
    "                kind=\"bar\",\n",
    "                ci=None,\n",
    "                palette='viridis'\n",
    "               ).set_axis_labels(\"Faixa Etária\", \"Parcela Mensal\", size=20, fontweight=\"bold\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677cc3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agegroup = df_nonull_uniqueCID.copy()\n",
    "\n",
    "df_agegroup[\"Age_Group\"] = pd.cut(df_agegroup.Age,\n",
    "                             bins=[14, 25, 30, 45, 60, 100],\n",
    "                             labels=[\"14-25\", \"25-30\", \"30-45\", \"45-60\", \"60-100\"],\n",
    "                            )\n",
    "\n",
    "age_groups = (df_agegroup.groupby([\"Age_Group\", \"Credit_Score\"])[\"Outstanding_Debt\", \"Annual_Income\", \"Num_Bank_Accounts\", \"Num_Credit_Card\",\"Credit_Utilization_Ratio\"].sum().reset_index())\n",
    "\n",
    "sns.catplot(data=age_groups,\n",
    "                x=\"Age_Group\",\n",
    "                y=\"Credit_Utilization_Ratio\",\n",
    "                height=7,\n",
    "                aspect=1,\n",
    "                col=\"Credit_Score\",\n",
    "                kind=\"bar\",\n",
    "                ci=None,\n",
    "                palette='viridis'\n",
    "               ).set_axis_labels(\"Faixa Etária\", \"Uso do Crédito\", size=20, fontweight=\"bold\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff184a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nonull_uniqueCID.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bebb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordem1 = df_nonull_uniqueCID.groupby(['Credit_Score'])['Delay_from_due_date'].mean().sort_values().index\n",
    "\n",
    "sns.barplot(data = df_nonull_uniqueCID,\n",
    "            x='Delay_from_due_date',\n",
    "            y='Credit_Score',\n",
    "            ci = None,\n",
    "            order = ordem1)\n",
    "plt.title('Média de Atraso x Credit Score')\n",
    "plt.xlabel('')\n",
    "plt.ylabel('')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10825589",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordem1 = df_nonull_uniqueCID.groupby(['Credit_Score'])['Num_of_Delayed_Payment'].mean().sort_values().index\n",
    "\n",
    "sns.barplot(data = df_nonull_uniqueCID,\n",
    "            x='Num_of_Delayed_Payment',\n",
    "            y='Credit_Score',\n",
    "            ci = None,\n",
    "            order = ordem1)\n",
    "plt.title('Média qtd. de Atrasos x Crédito Score')\n",
    "plt.xlabel('')\n",
    "plt.ylabel('')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898a67e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordem2 = df_nonull_uniqueCID.groupby(['Credit_Score'])['Monthly_Inhand_Salary'].mean().sort_values().index\n",
    "\n",
    "sns.barplot(data = df_nonull_uniqueCID,\n",
    "            x='Monthly_Inhand_Salary',\n",
    "            y='Credit_Score',\n",
    "            ci = None,\n",
    "            order = ordem2)\n",
    "\n",
    "plt.title('Salário x Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca11d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordem2 = df_nonull_uniqueCID.groupby(['Credit_Score'])['Credit_History_age'].mean().sort_values().index\n",
    "\n",
    "sns.barplot(data = df_nonull_uniqueCID,\n",
    "            x='Credit_History_age',\n",
    "            y='Credit_Score',\n",
    "            ci = None,\n",
    "            order = ordem2)\n",
    "\n",
    "plt.title('Historico de crédito x Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d04cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize = (10,10))\n",
    "\n",
    "sns.histplot(data = df_nonull_uniqueCID[df_nonull_uniqueCID['Credit_Score'] == 'Poor'], x = 'Monthly_Inhand_Salary', ax = axs[0], color = 'skyblue')\n",
    "sns.histplot(data = df_nonull_uniqueCID[df_nonull_uniqueCID['Credit_Score'] == 'Standard'], x = 'Monthly_Inhand_Salary', ax = axs[1], color = 'orange')\n",
    "sns.histplot(data = df_nonull_uniqueCID[df_nonull_uniqueCID['Credit_Score'] == 'Good'], x = 'Monthly_Inhand_Salary', ax = axs[2], color = 'teal')\n",
    "\n",
    "fig.suptitle('Distribuição de Salário por Score (Poor, Standard, Good)', size = 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0ea461",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordem1 = df_nonull_uniqueCID.groupby(['Occupation'])['Delay_from_due_date'].mean().sort_values().index\n",
    "\n",
    "sns.barplot(data = df_nonull_uniqueCID,\n",
    "            x='Delay_from_due_date',\n",
    "            y='Occupation',\n",
    "            ci = None,\n",
    "            order = ordem1,\n",
    "            palette='viridis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95fde36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot = df_nonull_uniqueCID.groupby(['Occupation', 'Credit_Score']).size().reset_index().pivot(columns='Credit_Score', index='Occupation', values=0)\n",
    "\n",
    "df_plot.plot(kind='bar', stacked=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6074d210",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordem1 = df_nonull_uniqueCID.groupby(['Occupation'])['Outstanding_Debt'].mean().sort_values().index\n",
    "\n",
    "sns.barplot(data = df_nonull_uniqueCID,\n",
    "            x='Outstanding_Debt',\n",
    "            y='Occupation',\n",
    "            ci = None,\n",
    "            order = ordem1,\n",
    "            palette='viridis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fa39f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numCols = df_total.select_dtypes([np.number]).columns\n",
    "\n",
    "# for col in numCols:\n",
    "#     fig, ax = plt.subplots(1, 2, figsize = (8,8))\n",
    "#     sns.boxplot(data=df_total, y=col, x = 'Credit_Score', ax=ax[0])\n",
    "#     sns.scatterplot(data=df_total,x = 'Credit_Score', s = 100, y=col, ax=ax[1], color ='#ee1199')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb640983",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "\n",
    "plt.pie(df_nonull_uniqueCID.Credit_Score.value_counts(normalize=True),\n",
    "        labels=['Standard', 'Poor', 'Good'],\n",
    "        textprops={'fontsize': 21},\n",
    "        colors = sns.color_palette('viridis')[1:6:2],\n",
    "        autopct='%.0f%%'\n",
    "        )\n",
    "\n",
    "plt.suptitle(\"Distribuição de Score\")\n",
    "plt.subplots_adjust(top=0.80)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa05612a-1b62-49c1-866a-286b285693eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(20,18))\n",
    "# sns.heatmap(df_total.corr(),annot=True,cmap='viridis', linewidths=1, linecolor='k', fmt='.2f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad9747b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25,6))\n",
    "sns.violinplot(x='Payment_Behaviour',y='Age',data=df_nonull_uniqueCID, hue='Credit_Score', palette='rainbow')\n",
    "plt.title(\"Distribuição de idade por perfil de pagamento\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41ef494",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25,6))\n",
    "sns.violinplot(x='Payment_Behaviour',y='Credit_Utilization_Ratio',data=df_nonull_uniqueCID, hue='Credit_Score', palette='rainbow')\n",
    "plt.title(\"Distribuição de utilização de crédito x Perfil de pagamento\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52da9d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(59,1))\n",
    "sns.displot(data=df_nonull_uniqueCID, x=\"Credit_Utilization_Ratio\", kde=True, color='#087E8B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863e7f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "nome_dict = {'Month': 'Mês',\n",
    "             'Age': 'Idade',\n",
    "             'Annual_Income': 'Renda Anual',\n",
    "             'Monthly_Inhand_Salary': 'Salário Mensal',\n",
    "             'Num_Bank_Accounts': 'Qtd. Contas',\n",
    "             'Num_Credit_Card': 'Qtd. Cartões',\n",
    "             'Interest_Rate': 'Taxa de Juros',\n",
    "             'Num_of_Loan': 'Qtd. Empréstimos',\n",
    "             'Delay_from_due_date': 'Atraso no pgto.',\n",
    "             'Num_of_Delayed_Payment': 'Qtd. Atrasos',\n",
    "             'Changed_Credit_Limit': 'Fator de troca do Limite de Crédito',\n",
    "             'Num_Credit_Inquiries': 'Qtd. de Cobranças',\n",
    "             'Outstanding_Debt': 'Dívida Pendente',\n",
    "             'Credit_Utilization_Ratio': 'Taxa de Utilização de Crédito',\n",
    "             'Total_EMI_per_month': 'Valor mensal prestação',\n",
    "             'Amount_invested_monthly': 'Valor investido mensalmente',\n",
    "             'Monthly_Balance': 'Saldo mensal',\n",
    "             'Credit_History_age': 'Idade de Histórico de Crédito'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb5b9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize= (15,9))\n",
    "\n",
    "num_cols = list(df_nonull_uniqueCID.select_dtypes(exclude='object').columns)\n",
    "\n",
    "for i, col in enumerate(num_cols):\n",
    "    ax=fig.add_subplot(4,5,i+1)      \n",
    "    sns.boxplot(x=df_total[col], ax=ax)\n",
    "    plt.xlabel(nome_dict[col])\n",
    "    fig.tight_layout()\n",
    "\n",
    "fig.suptitle('Distribuição de variáveis - Sem Limpeza IQR\\n', size = 24)\n",
    "plt.subplots_adjust(top=0.90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbba93d7",
   "metadata": {},
   "source": [
    "<a id=\"title-three\"></a>\n",
    "<h1 style='background:#3f4788; border:2; border-radius: 10px; color:white;padding:20px'><center>Limpeza de Dados</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024e6fb4",
   "metadata": {},
   "source": [
    "### Limpando outliers\n",
    "\n",
    "* Idade - Clientes entre 18 e 100 anos;\n",
    "* IQR nas variáveis numéricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3279e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aplicando IQR para as colunas numéricas\n",
    "# a coluna age sera tratada limitando idades entre 0 e 100 anos\n",
    "\n",
    "print('Número de linhas pré-limpeza: ', df_nonull_uniqueCID.shape[0])\n",
    "\n",
    "# Age\n",
    "\n",
    "indice_age = df_nonull_uniqueCID[(df_nonull_uniqueCID['Age'] <= 18) | (df_nonull_uniqueCID['Age'] >= 100)].index\n",
    "\n",
    "df_nonull_uniqueCID.drop(indice_age, inplace=True)\n",
    "\n",
    "# Restante das colunas numéricas\n",
    "\n",
    "for i in ['Num_of_Loan', 'Num_Bank_Accounts', 'Num_Credit_Card', 'Delay_from_due_date', 'Annual_Income',\n",
    "          'Interest_Rate', 'Num_of_Delayed_Payment', 'Num_Credit_Inquiries', 'Total_EMI_per_month',\n",
    "          'Amount_invested_monthly', 'Monthly_Balance']:\n",
    "\n",
    "    q1, q3 = np.percentile(df_nonull_uniqueCID[i], [25, 75])\n",
    "    \n",
    "    iqr = q3 - q1\n",
    "    lim_inf = q1 - 1.5 * iqr\n",
    "    lim_sup = q3 + 1.5 * iqr\n",
    "    indice = df_nonull_uniqueCID[(df_nonull_uniqueCID[i] <= 0) | (df_nonull_uniqueCID[i] >= lim_sup)].index\n",
    "    df_nonull_uniqueCID.drop(indice, inplace=True)\n",
    "\n",
    "print('Número de linhas pós limpeza: ', df_nonull_uniqueCID.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0891c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize= (15,9))\n",
    "\n",
    "for i, col in enumerate(num_cols):\n",
    "    ax=fig.add_subplot(4,5,i+1)      \n",
    "    sns.boxplot(x=df_nonull_uniqueCID[col], ax=ax)\n",
    "    plt.xlabel(nome_dict[col])\n",
    "    fig.tight_layout()\n",
    "\n",
    "fig.suptitle('Distribuição de variáveis - Com Limpeza IQR\\n', size = 24)\n",
    "plt.subplots_adjust(top=0.90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab3e81b",
   "metadata": {},
   "source": [
    "<a id=\"title-four\"></a>\n",
    "<h1 style='background:#3f4788; border:2; border-radius: 10px; color:white;padding:20px'><center>Pré-processamento de Dados</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c6aa85",
   "metadata": {},
   "source": [
    "### Drops vars. inúteis, Normalização, Encoding, Splits etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ab92a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "\n",
    "df_processado = df_nonull_uniqueCID.copy()\n",
    "df_processado = df_processado.drop(['Customer_ID', 'Name', 'SSN', 'Type_of_Loan', 'Type_of_Loan_ajustado',\n",
    "                                    'Credit_History_Age', 'Credit_Score', 'Month', 'Monthly_Balance',\n",
    "                                    'Occupation', 'Payment_Behaviour'], axis=1)\n",
    "\n",
    "#Pegando variáveis categóricas e numéricas\n",
    "\n",
    "categorical = list(df_processado.select_dtypes(include=['object']).columns)  #Talvez criar no começo pra visualizaçao describe().transpose()\n",
    "numerical = list(df_processado.select_dtypes(include=['int64', 'float64']).columns) #Talvez criar no começo pra visualizaçao describe()\n",
    "\n",
    "# Dummy Encoder para variáveis categóricas\n",
    "\n",
    "df_processado_categoricals = pd.DataFrame(columns = categorical, index = df_processado.index)\n",
    "for col in df_processado.select_dtypes('object'):\n",
    "    df_processado_categoricals[col], _ = df_processado[col].factorize()\n",
    "\n",
    "#Scaling para variáveis numéricas\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "stdscaler = StandardScaler()\n",
    "\n",
    "df_processado_numericals = pd.DataFrame(stdscaler.fit_transform(df_processado[numerical]), columns = numerical, index = df_processado_categoricals.index)\n",
    "\n",
    "#Concatenando categóricas encodadas e numéricas escaladas\n",
    "\n",
    "df_processado_final = pd.concat([df_processado_numericals, df_processado_categoricals], axis=1)\n",
    "\n",
    "#Ordinal Encoder na target\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "ordenc = OrdinalEncoder()\n",
    "\n",
    "df_processado_final['Credit_Score'] = ordenc.fit_transform(df_nonull_uniqueCID['Credit_Score'].values.reshape(-1,1)).astype(int)\n",
    "\n",
    "#Definindo X e y\n",
    "\n",
    "X = df_processado_final.drop(['Credit_Score'], axis = 1)\n",
    "y = df_processado_final['Credit_Score']\n",
    "\n",
    "X_todas_feats = df_nonull_uniqueCID.drop(['Customer_ID', 'Name', 'SSN', 'Type_of_Loan', 'Type_of_Loan_ajustado'], axis=1)\n",
    "for col in X_todas_feats.select_dtypes('object'):\n",
    "    X_todas_feats[col], _ = X_todas_feats[col].factorize()\n",
    "    \n",
    "for col in X_todas_feats.select_dtypes(['int64', 'float64']):\n",
    "    X_todas_feats[col] = stdscaler.fit_transform(X_todas_feats[col].values.reshape(-1,1))\n",
    "\n",
    "#Splitando o dataframe processado\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify = y, random_state=42)\n",
    "\n",
    "X_train_todas_feats, X_test_todas_feats, y_train_todas_feats, y_test_todas_feats = train_test_split(X_todas_feats, y, test_size=0.2, stratify = y, random_state=42)\n",
    "\n",
    "print('Shape dos splits com features seleciondadas (X_train, X_test, y_train, y_test): ')\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "print('\\nShape dos splits com todas as features (\"): ')\n",
    "print(X_train_todas_feats.shape, X_test_todas_feats.shape, y_train_todas_feats.shape, y_test_todas_feats.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aab12aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Encoding da target: ',{'0': ordenc.categories_[0][0],\n",
    "       '1': ordenc.categories_[0][1],\n",
    "       '2': ordenc.categories_[0][2]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b68c51",
   "metadata": {},
   "source": [
    "<a id=\"title-five\"></a>\n",
    "<h1 style='background:#3f4788; border:2; border-radius: 10px; color:white;padding:20px'><center>Feature Importance e Feature Selection</center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c1851a-f264-499c-8487-90238fb0a833",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processado_final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a461ddd-9024-4647-a5f6-af9d8e6e2466",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp = ['Outstanding_Debt','Delay_from_due_date','Changed_Credit_Limit','Credit_History_age',\n",
    "            'Monthly_Inhand_Salary','Num_of_Delayed_Payment','Credit_Utilization_Ratio', 'Credit_Score']\n",
    "\n",
    "sns.pairplot(df_processado_final[feat_imp], hue='Credit_Score', palette='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9712bb95-6c2b-49ba-8b0e-c0f356499a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Distribution(columne,data,i):\n",
    "    fig, ax = plt.subplots(1,2, figsize = (15,5))\n",
    "    font_dict = {'fontsize': 14}\n",
    "    title=['Antes do processamento','Depois do processamento']\n",
    "    ax = np.ravel(ax)\n",
    "    if i==1:\n",
    "        sns.set(style='whitegrid')\n",
    "        sns.kdeplot(data=data,x=columne, ax = ax[0],color='r').set_title(title[i])\n",
    "        sns.boxplot(data=data,x=columne, ax = ax[1],palette='magma').set_title(title[i])\n",
    "    else:\n",
    "        sns.set(style='whitegrid')\n",
    "        sns.kdeplot(data=data,x=columne, ax = ax[0],color='#2171b5').set_title(title[i])\n",
    "        sns.boxplot(data=data,x=columne, ax = ax[1],color='#2171b5').set_title(title[i])\n",
    "        \n",
    "    ax = np.reshape(ax, (1, 2))\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee3a126-0d26-4772-9db2-b64a257bccb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Distribution(columne = 'Outstanding_Debt', data = df_nonull_uniqueCID, i = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421752e7-784c-446f-8674-992ded580eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "Distribution(columne = 'Outstanding_Debt', data = df_processado_final, i = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9567a67-5ae7-4f07-9d87-d139df73e522",
   "metadata": {},
   "outputs": [],
   "source": [
    "from turtle import color\n",
    "\n",
    "\n",
    "sns.pairplot(df_processado_final,\n",
    "             x_vars=['Monthly_Inhand_Salary','Outstanding_Debt'],\n",
    "             y_vars=['Changed_Credit_Limit','Credit_Utilization_Ratio'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9502fa4",
   "metadata": {},
   "source": [
    "<a id=\"title-five\"></a>\n",
    "<h1 style='background:#3f4788; border:2; border-radius: 10px; color:white;padding:20px'><center>Feature Selection e Feature Importance</center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108abacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo Statsmodels para teste de hipótese e seleção de features\n",
    "\n",
    "# X_train = sm.add_constant(X_train)\n",
    "# X_test = sm.add_constant(X_test)\n",
    "\n",
    "model = sm.OLS(y_train, X_train)\n",
    "non_reg_OLS = model.fit()\n",
    "non_reg_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1834ac18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#VIF\n",
    "def calc_vif(data):\n",
    "    vif_df = pd.DataFrame(columns=['Var', 'VIF'])\n",
    "    x_var_names = data.columns\n",
    "    \n",
    "    for i in range(0, x_var_names.shape[0]):\n",
    "        y = data[x_var_names[i]]\n",
    "        x = data[x_var_names.drop(x_var_names[i])]\n",
    "        r2 = sm.OLS(y, x).fit().rsquared\n",
    "        vif = round(1/(1-r2),3)\n",
    "        vif_df.loc[i] = [x_var_names[i], vif]\n",
    "    return vif_df.sort_values(by='VIF',axis = 0, ascending=False, inplace=False)\n",
    "\n",
    "calc_vif(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf2c219",
   "metadata": {},
   "source": [
    "### * ExtraTreeClassifier - método model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e5c3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ExtraTreeClassifier para feature_importances_\n",
    "\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "\n",
    "xtc = ExtraTreeClassifier()\n",
    "xtc.fit(X_train, y_train)\n",
    "feat_importance = pd.Series(xtc.feature_importances_, index=X_train.columns).sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(20,8))\n",
    "feat_importance.plot(kind='bar', color='#087E8B')\n",
    "plt.xticks(fontsize=19);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe729f8",
   "metadata": {},
   "source": [
    "### *PCA - Visualização e Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56486b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualização da Análise de Componentes Principais (PCA)\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA().fit(X_train)\n",
    "\n",
    "plt.plot(pca.explained_variance_ratio_.cumsum(), lw=3, color='#087E8B')\n",
    "plt.axhline(0.7, ls='--', color='k')\n",
    "plt.axvline(6, ls='--', color='k')\n",
    "plt.text(7.4, 0.72, '70% da variância', fontsize=14)\n",
    "plt.text(6.2, 0.43, '6 componentes', fontsize=14)\n",
    "plt.title('Variância cumulativa explicada por número de componentes principais', size=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7bcdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Número de componentes principais para explicar pelo menos 70% da variância: {}'.format(np.argmax(pca.explained_variance_ratio_.cumsum() > 0.7)+1))\n",
    "print(f'9 Componentes principais explicam: {pca.explained_variance_ratio_[:4].sum().round(4)*100}% da variância')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f181b26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loadings = pd.DataFrame(\n",
    "    data=pca.components_.T * np.sqrt(pca.explained_variance_), \n",
    "    columns=[f'PC{i}' for i in range(1, len(X_train.columns) + 1)],\n",
    "    index=X_train.columns\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(24,14))\n",
    "sns.heatmap(loadings.iloc[:,:np.argmax(pca.explained_variance_ratio_.cumsum() > 0.7)+2], annot=True, cmap='viridis', linewidths=1, linecolor='k', fmt='.2f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44ccd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc1_loadings = loadings.sort_values(by='PC1', ascending=False)[['PC1']]\n",
    "pc1_loadings = pc1_loadings.reset_index()\n",
    "pc1_loadings.columns = ['Attribute', 'CorrelationWithPC1']\n",
    "\n",
    "plt.bar(x=pc1_loadings['Attribute'], height=pc1_loadings['CorrelationWithPC1'], color='#087E8B')\n",
    "plt.title('PCA loading scores (first principal component)', size=20)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d41301f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from turtle import color\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "def make_mi_scores(X, y, discrete_features):\n",
    "    mi_scores = mutual_info_regression(X, y, discrete_features=discrete_features)\n",
    "    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n",
    "    mi_scores = mi_scores.sort_values(ascending=False)\n",
    "    return mi_scores\n",
    "\n",
    "def plot_mi_scores(scores):\n",
    "    scores = scores.sort_values(ascending=True)\n",
    "    width = np.arange(len(scores))\n",
    "    ticks = list(scores.index)\n",
    "    plt.barh(width, scores, color='#087E8B')\n",
    "    plt.yticks(width, ticks)\n",
    "    plt.title(\"Mutual Information Scores\")\n",
    "\n",
    "discrete_features = X.dtypes == int\n",
    "mi_scores = make_mi_scores(X, y, discrete_features)\n",
    "\n",
    "print(mi_scores)\n",
    "plt.figure(dpi=100, figsize=(8, 5))\n",
    "plot_mi_scores(mi_scores)\n",
    "plt.axvline(0.2, color='k', linestyle='--')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417ee7da",
   "metadata": {},
   "source": [
    "### Meme do homem-aranha apontando pro homem-aranha\n",
    "\n",
    "<img src='img/meme-homem-aranha.JPG' width=30% height=40%>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c353294",
   "metadata": {},
   "source": [
    "<a id=\"title-six\"></a>\n",
    "<h1 style='background:#3f4788; border:2; border-radius: 10px; color:white;padding:20px'><center>Modelagem</center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b61a880",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report, roc_auc_score, roc_curve, auc, accuracy_score, f1_score, precision_score, recall_score, accuracy_score\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier, StackingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "from skopt import BayesSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2214a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando comparação de acurácia entre os 5 modelos escolhidos\n",
    "\n",
    "comparacao_modelos = pd.DataFrame(columns = ['Modelo', 'Score'])\n",
    "\n",
    "modelos = [LogisticRegression(solver='liblinear', random_state=42),\n",
    "           KNeighborsClassifier(n_neighbors=41, p=4),\n",
    "           DecisionTreeClassifier(random_state=42),\n",
    "           RandomForestClassifier(random_state=42),\n",
    "           XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),\n",
    "           ExtraTreeClassifier(random_state=42),\n",
    "           MLPClassifier(solver='sgd', random_state=42, max_iter=500),\n",
    "           ]\n",
    "\n",
    "for model in modelos:\n",
    "    model_name = model.__class__.__name__\n",
    "    scores = cross_val_score(model, X_train, y_train, cv = 5, scoring = 'accuracy')\n",
    "    comparacao_modelos.loc[len(comparacao_modelos)] = [model_name, scores.mean().round(4)]\n",
    "\n",
    "print('* Comparação Cross-Validation-Score entre vários modelos: ')\n",
    "comparacao_modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519b6fb6",
   "metadata": {},
   "source": [
    "### Modelo Baseline: Dummy Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49837670",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummymodel = DummyClassifier(strategy='prior')\n",
    "dummymodel.fit(X_train, y_train)\n",
    "\n",
    "y_pred_dummy = dummymodel.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5025ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(y_test, y_pred_dummy))\n",
    "cmp1 = ConfusionMatrixDisplay(confusion_matrix(y_test, y_pred_dummy), display_labels=['Good', 'Poor', 'Standard'])\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "plt.grid(False)\n",
    "cmp1.plot(ax=ax)\n",
    "plt.rc('font', **font)\n",
    "plt.title('Matriz de confusão - Dummy Classifier', fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7d6ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_auc_dummy = roc_auc_score(y_test, dummymodel.predict_proba(X_test), multi_class = 'ovo')\n",
    "print('Dummy Classifier tem AUROC = %.3f' % (r_auc_dummy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43385e9c",
   "metadata": {},
   "source": [
    "### 1º Modelo: Extra Trees Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16937a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Otimização Bayesiana de hiperparâmetros\n",
    "# xtclf = ExtraTreesClassifier(n_jobs=-1)\n",
    "# xt_params = {'n_estimators':[2000],\n",
    "#                 'criterion': ['gini'],\n",
    "#                 'bootstrap':[True]\n",
    "#                 }\n",
    "\n",
    "# bayessearch_xt = BayesSearchCV(xtclf,\n",
    "#                                   xt_params,\n",
    "#                                   cv=5,\n",
    "#                                   refit=['accuracy', 'f1'],\n",
    "#                                   n_jobs=-1,\n",
    "#                                   verbose=1,\n",
    "#                                   random_state=42\n",
    "#                                   ).fit(X_train, y_train)\n",
    "\n",
    "# y_pred_xt = bayessearch_xt.predict(X_test)\n",
    "# bayessearch_xt.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1421907a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OrderedDict([('bootstrap', True),\n",
    "#              ('criterion', 'gini'),\n",
    "#              ('n_estimators', 2000)])\n",
    "\n",
    "xtclf = ExtraTreesClassifier(n_jobs=-1,\n",
    "                             bootstrap=True,\n",
    "                             criterion='gini',\n",
    "                             n_estimators=2000).fit(X_train, y_train)\n",
    "\n",
    "y_pred_xt = xtclf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c1aa4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_xt))\n",
    "cmp1 = ConfusionMatrixDisplay(confusion_matrix(y_test, y_pred_xt), display_labels=['Good', 'Poor', 'Standard'])\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "plt.grid(False)\n",
    "cmp1.plot(ax=ax)\n",
    "plt.rc('font', **font)\n",
    "plt.title('Matriz de confusão - Extra Trees', fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fecb5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_auc_xt = roc_auc_score(y_test, xtclf.predict_proba(X_test), multi_class = 'ovo')\n",
    "print('Extra Trees tem AUROC = %.3f' % (r_auc_xt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba378ff",
   "metadata": {},
   "source": [
    "### 2º Modelo: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47627ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Otimização Bayesiana de hiperparâmetros\n",
    "# rfclassifier = RandomForestClassifier(random_state = 42, n_jobs = -1)\n",
    "# rf_params = {'n_estimators': [500, 1500],\n",
    "#               'max_depth': [None],\n",
    "#               'criterion': ['gini']\n",
    "#                }\n",
    "\n",
    "# bayessearch_rf = BayesSearchCV(rfclassifier,\n",
    "#                                rf_params,\n",
    "#                                cv = 5,\n",
    "#                                scoring = 'accuracy',\n",
    "#                                n_jobs = -1,\n",
    "#                                verbose = 1,\n",
    "#                                refit = 'accuracy'\n",
    "#                                ).fit(X_train, y_train)\n",
    "\n",
    "# y_pred_rf = bayessearch_rf.predict(X_test)\n",
    "# bayessearch_rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0519d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OrderedDict([('criterion', 'gini'),\n",
    "#              ('max_depth', None),\n",
    "#              ('n_estimators', 1441)])\n",
    "\n",
    "rfclf = RandomForestClassifier(random_state = 42,\n",
    "                               n_jobs = -1,\n",
    "                               criterion = 'gini',\n",
    "                               max_depth = None,\n",
    "                               n_estimators = 1441).fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rfclf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f51044",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_rf))\n",
    "cmp1 = ConfusionMatrixDisplay(confusion_matrix(y_test, y_pred_rf), display_labels=['Good', 'Poor', 'Standard'])\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "plt.grid(False)\n",
    "cmp1.plot(ax=ax)\n",
    "plt.rc('font', **font)\n",
    "plt.title('Matriz de confusão - Random Forest', fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc2f826",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_auc_rf = roc_auc_score(y_test, rfclf.predict_proba(X_test), multi_class = 'ovo')\n",
    "print('Random Forest tem AUROC = %.3f' % (r_auc_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e5f9b1",
   "metadata": {},
   "source": [
    "### 3º Modelo: XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e359a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Otimização Bayesiana de hiperparâmetros\n",
    "# xgbclassifier = XGBClassifier(eval_metric = 'logloss', use_label_encoder = False, random_state = 42)\n",
    "\n",
    "# xgb_params = {'n_estimators': [5, 750, 1500],\n",
    "#               'max_depth': [None],\n",
    "#               'gamma': [0.5, 1, 5],\n",
    "#               'subsample': [0.2, 1.0],\n",
    "#               'colsample_bytree': [0.6, 0.8],\n",
    "#               'min_child_weight': [0.3, 0.7, 1.0],\n",
    "#               'learning_rate': [0.1, 0.3]\n",
    "#                }\n",
    "\n",
    "# OrderedDict([('colsample_bytree', 0.6),\n",
    "#              ('gamma', 1.0),\n",
    "#              ('learning_rate', 0.1),\n",
    "#              ('max_depth', None),\n",
    "#              ('min_child_weight', 0.7),\n",
    "#              ('n_estimators', 1500),\n",
    "#              ('subsample', 1.0)])\n",
    "\n",
    "# bayessearch_xgbc = BayesSearchCV(xgbclassifier,\n",
    "#                                  xgb_params,\n",
    "#                                  cv = 5,\n",
    "#                                  scoring = 'accuracy',\n",
    "#                                  refit = 'accuracy',\n",
    "#                                  verbose = 1,\n",
    "#                                  n_jobs = -1\n",
    "#                                  ).fit(X_train, y_train)\n",
    "\n",
    "# y_pred_xgbc = bayessearch_xgbc.predict(X_test)\n",
    "# bayessearch_xgbc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef77115",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbclassifier = XGBClassifier(eval_metric = 'logloss',\n",
    "                              use_label_encoder = False,\n",
    "                              random_state = 42,\n",
    "                              colsample_bytree = 0.6,\n",
    "                              gamma = 1.0,\n",
    "                              learning_rate = 0.1,\n",
    "                              max_depth = None,\n",
    "                              min_child_weight = 0.7,\n",
    "                              n_estimators = 1500,\n",
    "                              subsample = 1.0).fit(X_test, y_test)\n",
    "\n",
    "y_pred_xgbc = xgbclassifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98fac99",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_xgbc))\n",
    "cmp1 = ConfusionMatrixDisplay(confusion_matrix(y_test, y_pred_xgbc), display_labels=['Good', 'Poor', 'Standard'])\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "plt.grid(False)\n",
    "cmp1.plot(ax=ax)\n",
    "plt.rc('font', **font)\n",
    "plt.title('Matriz de confusão - XGBoost', fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df869e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_auc_xgbc = roc_auc_score(y_test, xgbclassifier.predict_proba(X_test), multi_class = 'ovo')\n",
    "print('XGBoost tem AUROC = %.3f' % (r_auc_xgbc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e977371",
   "metadata": {},
   "source": [
    "### 4º Modelo: Multi-Layer Perceptron (Rede Neural SKLearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43bd1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Otimização Bayesiana de hiperparâmetros\n",
    "# mlpc = MLPClassifier(random_state = 42, max_iter = 500)\n",
    "\n",
    "# mlp_params = {'hidden_layer_sizes': [100, 200, 400],\n",
    "#               'activation': ['tanh'],\n",
    "#               'solver': ['sgd', 'adam'],\n",
    "#               'alpha': [0.001, 0.1, 0.3],\n",
    "#               'learning_rate': ['constant', 'invscaling']\n",
    "#               }\n",
    "\n",
    "# bayessearch_mlpc = BayesSearchCV(mlpc,\n",
    "#                                  mlp_params,\n",
    "#                                  cv = 3,\n",
    "#                                  scoring = 'accuracy',\n",
    "#                                  refit = 'accuracy',\n",
    "#                                  verbose = 1,\n",
    "#                                  n_jobs = -1\n",
    "#                                  ).fit(X_train, y_train)\n",
    "\n",
    "# y_pred_mlpc = bayessearch_mlpc.predict(X_test)\n",
    "# bayessearch_mlpc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6407dbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlpc = MLPClassifier(activation='tanh',\n",
    "                     alpha=0.1,\n",
    "                     hidden_layer_sizes=100,\n",
    "                     learning_rate='invscaling',\n",
    "                     solver='adam',\n",
    "                     random_state = 42,\n",
    "                     max_iter = 500,\n",
    "                     warm_start=True).fit(X_train, y_train)\n",
    "\n",
    "y_pred_mlpc = mlpc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc6fc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_mlpc))\n",
    "cmp1 = ConfusionMatrixDisplay(confusion_matrix(y_test, y_pred_mlpc), display_labels=['Good', 'Poor', 'Standard'])\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "plt.grid(False)\n",
    "cmp1.plot(ax=ax)\n",
    "plt.rc('font', **font)\n",
    "plt.title('Matriz de confusão - Multi-Layer Perceptron', fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df639d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_auc_mlp = roc_auc_score(y_test, mlpc.predict_proba(X_test), multi_class = 'ovo')\n",
    "print('MLP Classifier tem AUROC = %.3f' % (r_auc_mlp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e5f9b1",
   "metadata": {},
   "source": [
    "### 5º Modelo: Stacking de XGBoost com SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071fc1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Otimização Bayesiana de hiperparâmetros\n",
    "# svc = SVC(random_state=42, max_iter=200)\n",
    "\n",
    "# svc_params = {'probability': [True, False],\n",
    "#               'kernel': ['rbf', 'linear', 'poly'],\n",
    "#               'degree': [2, 3, 4],\n",
    "#               'C': [0.1, 1.0, 10.0],\n",
    "#               'gamma': ['scale', 'auto'],\n",
    "#               'tol': [1e-5],\n",
    "#               'shrinking': [True, False]\n",
    "#               }\n",
    "\n",
    "# bayessearch_svc = BayesSearchCV(svc,\n",
    "#                                 svc_params,\n",
    "#                                 cv = 3,\n",
    "#                                 scoring = 'accuracy',\n",
    "#                                 refit = 'accuracy',\n",
    "#                                 verbose = 1,\n",
    "#                                 n_jobs = -1,\n",
    "#                                 random_state=42).fit(X_train, y_train)\n",
    "\n",
    "# y_pred_mlpc = bayessearch_svc.predict(X_test)\n",
    "# bayessearch_svc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6407dbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [('xgbc', XGBClassifier(eval_metric = 'logloss',\n",
    "                                     use_label_encoder = False,\n",
    "                                     random_state = 42,\n",
    "                                     colsample_bytree = 0.6,\n",
    "                                     gamma = 1.0,\n",
    "                                     learning_rate = 0.1,\n",
    "                                     max_depth = None,\n",
    "                                     min_child_weight = 0.7,\n",
    "                                     n_estimators = 1500,\n",
    "                                     subsample = 1.0)),\n",
    "              \n",
    "              ('svc', SVC(random_state=42, \n",
    "                          C = 0.1,\n",
    "                          degree = 3,\n",
    "                          gamma ='scale',\n",
    "                          kernel = 'poly',\n",
    "                          probability = False,\n",
    "                          shrinking = True,\n",
    "                          tol = 1e-05))]\n",
    "\n",
    "stackingclf = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression(random_state=42, max_iter=400), cv=5).fit(X_train, y_train)\n",
    "\n",
    "y_pred_stacking = stackingclf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f51044",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_stacking))\n",
    "cmp1 = ConfusionMatrixDisplay(confusion_matrix(y_test, y_pred_stacking), display_labels=['Good', 'Poor', 'Standard'])\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "plt.grid(False)\n",
    "cmp1.plot(ax=ax)\n",
    "plt.rc('font', **font)\n",
    "plt.title('Matriz de confusão - Stacking XGBoost com SVC', fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc2f826",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_auc_stacking = roc_auc_score(y_test, stackingclf.predict_proba(X_test), multi_class = 'ovo')\n",
    "print('Stacking Classifier tem AUROC = %.3f' % (r_auc_stacking))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66e276e",
   "metadata": {},
   "source": [
    "## Comparativos dos modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe19a7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extra Trees: y_pred_xt\n",
    "#Random Forest: y_pred_rf\n",
    "#XGBoost: y_pred_xgbc;\n",
    "#Multi-Layer Perceptron: y_pred_mlpc\n",
    "#Stacking Classifier: y_pred_stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93c8d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_multiclass_roc(clf, X_test, y_test, n_classes, modelname, figsize=(17, 6)):\n",
    "    y_score = clf.predict_proba(X_test)\n",
    "\n",
    "    # structures\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "\n",
    "    # calculate dummies once\n",
    "    y_test_dummies = pd.get_dummies(y_test, drop_first=False).values\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test_dummies[:, i], y_score[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    # roc for each class\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    ax.plot([0, 1], [0, 1], 'k--')\n",
    "    ax.set_xlim([0.0, 1.0])\n",
    "    ax.set_ylim([0.0, 1.05])\n",
    "    ax.set_xlabel('False Positive Rate')\n",
    "    ax.set_ylabel('True Positive Rate')\n",
    "    ax.set_title(f'ROC curve - for {modelname}', fontdict={'fontsize': 26})\n",
    "    for i in range(n_classes):\n",
    "        ax.plot(fpr[i], tpr[i], label='ROC curve (area = %0.3f) for label %i' % (roc_auc[i], i))\n",
    "    ax.legend(loc=\"best\")\n",
    "    ax.grid(alpha=.4)\n",
    "    sns.despine()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9956e25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_multiclass_roc(dummymodel, X_test, y_test, n_classes = 3, modelname = 'Dummy Classifier', figsize = (16,10))\n",
    "plot_multiclass_roc(xtclf, X_test, y_test, 3, 'Extra Trees', (16, 10))\n",
    "plot_multiclass_roc(rfclf, X_test, y_test, 3, 'Random Forest', (16, 10))\n",
    "plot_multiclass_roc(xgbclassifier, X_test, y_test, 3, 'XGBoost', (16, 10))\n",
    "plot_multiclass_roc(mlpc, X_test, y_test, 3, 'Multi-Layer Perceptron', (16, 10))\n",
    "plot_multiclass_roc(stackingclf, X_test, y_test, 3, 'Stacking', (16, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9cf1f7c",
   "metadata": {},
   "source": [
    "#### Curvas ROC conjuntas (para a classe Standard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7427fcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_allmodels_roc(clf, X_test, y_test, figsize=(17, 6)):\n",
    "    y_score = []\n",
    "\n",
    "    # structures\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    \n",
    "    # calculate dummies once\n",
    "    y_test_dummies = pd.get_dummies(y_test, drop_first=False).values\n",
    "    \n",
    "    for i, it in zip(clf, range(len(clf))):\n",
    "        y_score = i.predict_proba(X_test)[:, 2]\n",
    "        fpr[it], tpr[it], _ = roc_curve(y_test_dummies[:, 2], y_score)\n",
    "        roc_auc[it] = auc(fpr[it], tpr[it])\n",
    "\n",
    "    # roc for each class\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    ax.plot([0, 1], [0, 1], 'k--', label='DummyClassifier (AUC = 0.500)')\n",
    "    ax.set_xlim([0.0, 1.0])\n",
    "    ax.set_ylim([0.0, 1.05])\n",
    "    ax.set_xlabel('False Positive Rate')\n",
    "    ax.set_ylabel('True Positive Rate')\n",
    "    ax.set_title(f'ROC curve for Standard Class (OvR) - All models', fontdict={'fontsize': 26})\n",
    "    \n",
    "    for i, it in zip(clf, range(len(clf))):\n",
    "        ax.plot(fpr[it], tpr[it], label='%s (AUC = %0.3f)' % (i.__class__.__name__, roc_auc[it]))\n",
    "        \n",
    "    ax.legend(loc=\"best\")\n",
    "    ax.grid(alpha=.4)\n",
    "    sns.despine()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40801efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_allmodels_roc([rfclf, xtclf, xgbclassifier, mlpc, stackingclf], X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de46333c",
   "metadata": {},
   "source": [
    "### Tabela comparativa de Métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3177ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perf_measure(y_actual, y_hat):\n",
    "   \n",
    "   metricas = []\n",
    "   TP, FP, TN, FN = 0, 0, 0, 0\n",
    "   \n",
    "   TP = confusion_matrix(y_actual, y_hat)[2][2]\n",
    "   FP = confusion_matrix(y_actual, y_hat)[0][2] + confusion_matrix(y_actual, y_hat)[1][2]\n",
    "   TN = confusion_matrix(y_actual, y_hat)[0][0] + confusion_matrix(y_actual, y_hat)[0][1] + confusion_matrix(y_actual, y_hat)[1][0] + confusion_matrix(y_actual, y_hat)[1][1]\n",
    "   FN = confusion_matrix(y_actual, y_hat)[2][0] + confusion_matrix(y_actual, y_hat)[2][1]\n",
    "   \n",
    "   metricas.append(TP)\n",
    "   metricas.append(FP)\n",
    "   metricas.append(TN)\n",
    "   metricas.append(FN)\n",
    "   \n",
    "   return metricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4174e4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparativo_final_metricas = pd.DataFrame(columns = ['Acurácia', 'Recall', 'FN', 'F1-Score', 'AUROC'])\n",
    "\n",
    "comparativo_final_metricas.loc['Dummy'] = [accuracy_score(y_test, y_pred_dummy).round(4),\n",
    "                                           recall_score(y_test, y_pred_dummy, average='macro').round(4),\n",
    "                                           perf_measure(y_test, y_pred_dummy)[3].sum(),\n",
    "                                           f1_score(y_test, y_pred_dummy, average='macro').round(4),\n",
    "                                           r_auc_dummy.round(4)\n",
    "                                           ]\n",
    "\n",
    "comparativo_final_metricas.loc['Extra Trees'] = [accuracy_score(y_test, y_pred_xt).round(4),\n",
    "                                                 recall_score(y_test, y_pred_xt, average='macro').round(4),\n",
    "                                                 perf_measure(y_test, y_pred_xt)[3].sum(),\n",
    "                                                 f1_score(y_test, y_pred_xt, average='macro').round(4),\n",
    "                                                 r_auc_xt.round(4)\n",
    "                                                 ]\n",
    "\n",
    "comparativo_final_metricas.loc['Random Forest'] = [accuracy_score(y_test, y_pred_rf).round(4),\n",
    "                                                   recall_score(y_test, y_pred_rf, average='macro').round(4),\n",
    "                                                   perf_measure(y_test, y_pred_rf)[3].sum(),\n",
    "                                                   f1_score(y_test, y_pred_rf, average='macro').round(4),\n",
    "                                                   r_auc_rf.round(4)\n",
    "                                                   ]\n",
    "\n",
    "comparativo_final_metricas.loc['XGBoost'] = [accuracy_score(y_test, y_pred_xgbc).round(4),\n",
    "                                             recall_score(y_test, y_pred_xgbc, average='macro').round(4),\n",
    "                                             perf_measure(y_test, y_pred_xgbc)[3].sum(),\n",
    "                                             f1_score(y_test, y_pred_xgbc, average='macro').round(4),\n",
    "                                             r_auc_xgbc.round(4)\n",
    "                                             ]\n",
    "\n",
    "comparativo_final_metricas.loc['Multi Layer Perceptron'] = [accuracy_score(y_test, y_pred_mlpc).round(4),\n",
    "                                                            recall_score(y_test, y_pred_mlpc, average='macro').round(4),\n",
    "                                                            perf_measure(y_test, y_pred_mlpc)[3].sum(),\n",
    "                                                            f1_score(y_test, y_pred_mlpc, average='macro').round(4),\n",
    "                                                            r_auc_rf.round(4)\n",
    "                                                            ]\n",
    "\n",
    "comparativo_final_metricas.loc['Stacking'] = [accuracy_score(y_test, y_pred_stacking).round(4),\n",
    "                                              recall_score(y_test, y_pred_stacking, average='macro').round(4),\n",
    "                                              perf_measure(y_test, y_pred_stacking)[3].sum(),\n",
    "                                              f1_score(y_test, y_pred_stacking, average='macro').round(4),\n",
    "                                              r_auc_stacking.round(4)\n",
    "                                              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa51458",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparativo_final_metricas = comparativo_final_metricas.sort_values(by='Acurácia', ascending=False)\n",
    "comparativo_final_metricas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0da2360",
   "metadata": {},
   "source": [
    "#### FIM"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "ec83e88ed8cedc03773fa1fb0e0d95e2e49f6d25892556d2f805fe0a6e2f7215"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
